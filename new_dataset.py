# -*- coding: utf-8 -*-
"""New dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17N1517MqeOrarALTs-6nExAOu5CZNvDU
"""

import pandas as pd

# Load the data
file_path = 'New folder (2)/flu-publichealthlab-byregion-fluseason.csv'
data = pd.read_csv(file_path)

# Display the first few rows of the dataframe
data.head()

# Display the column names
print(data.columns)

# Display summary information about the dataframe
data.info()

# Check for missing values
data.isnull().sum()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Load the data
file_path = 'New folder (2)/flu-publichealthlab-byregion-fluseason.csv'
data = pd.read_csv(file_path)

# Display the first few rows and column names of the dataframe
print(data.head())
print(data.columns)

# Preprocess the data
# Convert categorical columns to numeric using one-hot encoding
data_encoded = pd.get_dummies(data, columns=['season', 'region', 'Influenza_Category'])

# Define features and target
features = data_encoded.drop(columns=['Count', 'date_code', 'weekending'])
target = data_encoded['Count']

# Convert the target variable to a binary classification problem (e.g., outbreak vs. no outbreak)
# Here, we assume an outbreak if the count is above a certain threshold (e.g., mean count)
threshold = target.mean()
target_binary = (target > threshold).astype(int)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, target_binary, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Logistic Regression model
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train_scaled, y_train)
y_pred_log_reg = log_reg.predict(X_test_scaled)

# Random Forest model
rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
rf_clf.fit(X_train, y_train)
y_pred_rf = rf_clf.predict(X_test)

# Evaluate the models
log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg)
rf_accuracy = accuracy_score(y_test, y_pred_rf)

log_reg_conf_matrix = confusion_matrix(y_test, y_pred_log_reg)
rf_conf_matrix = confusion_matrix(y_test, y_pred_rf)

log_reg_report = classification_report(y_test, y_pred_log_reg)
rf_report = classification_report(y_test, y_pred_rf)
print('')
print((log_reg_accuracy, rf_accuracy), (log_reg_conf_matrix, rf_conf_matrix), (log_reg_report, rf_report))

import sqlite3
import pandas as pd

file_path = 'New folder (2)/flu-publichealthlab-byregion-fluseason.csv'
data = pd.read_csv(file_path)
print(data.head())

conn = sqlite3.connect('health_data.db')
cursor = conn.cursor()

create_table_query = '''
CREATE TABLE IF NOT EXISTS flu_data (
    season TEXT,
    date_code INTEGER,
    weekending TEXT,
    region TEXT,
    Influenza_Category TEXT,
    Count INTEGER
)
'''
cursor.execute(create_table_query)
conn.commit()

data.to_sql('flu_data', conn, if_exists='replace', index=False)

cursor.execute("SELECT * FROM flu_data LIMIT 5")
rows = cursor.fetchall()
for row in rows:
    print(row)

conn.close()


import pandas as pd
import numpy as np
import sqlite3
from flask import Flask, render_template, request
import plotly.express as px
import plotly.graph_objects as go

# Load the data
file_path = 'New folder (2)/flu-publichealthlab-byregion-fluseason.csv'
data = pd.read_csv(file_path)

# Preprocess the data
data_encoded = pd.get_dummies(data, columns=['season', 'region', 'Influenza_Category'])
features = data_encoded.drop(columns=['Count', 'date_code', 'weekending'])
target = data_encoded['Count']

# Convert the target variable to a binary classification problem
threshold = target.mean()
target_binary = (target > threshold).astype(int)

# Train a random forest model for predictions
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(features, target_binary, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
rf_clf.fit(X_train, y_train)

# Create Flask app
app = Flask(__name__)

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    # Extract form data
    form_data = request.form
    season = form_data['season']
    region = form_data['region']
    influenza_category = form_data['influenza_category']

    # Prepare the input data for prediction
    input_data = {
        'season': season,
        'region': region,
        'Influenza_Category': influenza_category,
    }

    input_df = pd.DataFrame([input_data])
    input_encoded = pd.get_dummies(input_df)
    input_encoded = input_encoded.reindex(columns=features.columns, fill_value=0)
    input_scaled = scaler.transform(input_encoded)

    # Make prediction
    prediction = rf_clf.predict(input_scaled)
    prediction_text = 'Outbreak' if prediction[0] == 1 else 'No Outbreak'

    return render_template('result.html', prediction=prediction_text ,logac= log_reg_accuracy,acc=rf_accuracy)

@app.route('/trends')
def trends():
    # Generate trends visualization
    fig = px.line(data, x='weekending', y='Count', color='region', title='Flu Cases Trends by Region')
    graph_html = fig.to_html(full_html=False)

    return render_template('trends.html', graph_html=graph_html)

if __name__ == '__main__':
    app.run()